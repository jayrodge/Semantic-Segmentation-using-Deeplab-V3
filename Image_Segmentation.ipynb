{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Segmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vMaKlFCYGqTW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "# os.chdir('portrait-mode/')\n",
        "import predict_depth\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from deeplab_model import DeepLabModel\n",
        "from monodepth_model import monodepth_parameters, MonodepthModel "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUKSl0szRcPK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pretrained_deeplabv3_path = 'models/deeplabv3_pascal_train_aug'\n",
        "pretrained_monodepth_path = 'models/model_city2kitti/model_city2kitti'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k8Zxt2dLRleh",
        "colab_type": "code",
        "outputId": "11be511c-6528-4ff0-d26e-3e35bed115a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "def post_process_disparity(disp):\n",
        "    _, h, w = disp.shape\n",
        "    l_disp = disp[0, :, :]\n",
        "    r_disp = np.fliplr(disp[1, :, :])\n",
        "    m_disp = 0.5 * (l_disp + r_disp)\n",
        "    l, _ = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))\n",
        "    l_mask = 1.0 - np.clip(20 * (l - 0.05), 0, 1)\n",
        "    r_mask = np.fliplr(l_mask)\n",
        "    return r_mask * l_disp + l_mask * r_disp + (1.0 - l_mask - r_mask) * m_disp\n",
        "\n",
        "INPUT_HEIGHT, INPUT_WIDTH = 512, 256\n",
        "params = monodepth_parameters(\n",
        "      encoder='vgg',\n",
        "      height=INPUT_HEIGHT,\n",
        "      width=INPUT_WIDTH,\n",
        "      batch_size=2,\n",
        "      num_threads=1,\n",
        "      num_epochs=1,\n",
        "      do_stereo=False,\n",
        "      wrap_mode=\"border\",\n",
        "      use_deconv=False,\n",
        "      alpha_image_loss=0,\n",
        "      disp_gradient_loss_weight=0,\n",
        "      lr_loss_weight=0,\n",
        "      full_summary=False)\n",
        "\n",
        "left = tf.placeholder(\n",
        "    tf.float32, [2, INPUT_HEIGHT, INPUT_WIDTH, 3])\n",
        "\n",
        "disp_model = MonodepthModel(params, \"test\", left, None)\n",
        "config = tf.ConfigProto(allow_soft_placement=True)\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.local_variables_initializer())\n",
        "\n",
        "\n",
        "def predict(input_image,model):\n",
        "  INPUT_HEIGHT, INPUT_WIDTH = 512, 256\n",
        "\n",
        "  input_image = cv2.resize(\n",
        "      input_image, (INPUT_WIDTH, INPUT_HEIGHT), cv2.INTER_AREA)\n",
        "  input_image = input_image.astype(np.float32) / 255\n",
        "  input_images = np.stack((input_image, np.fliplr(input_image)), 0)\n",
        "\n",
        "\n",
        "  disp = sess.run(model.disp_left_est[0], feed_dict={left: input_images})\n",
        "  disp_pp = post_process_disparity(disp.squeeze()).astype(np.float32)\n",
        "  \n",
        "  return disp_pp"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iVYaHJruRmVa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://cseweb.ucsd.edu/~weijian/static/datasets/celeba/img_align_celeba.zip\n",
        "!unzip img_align_celeba.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pYfRq9KAUo5c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#DeepLab Model\n",
        "ss_model = DeepLabModel(pretrained_deeplabv3_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jay7yWodUmCK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Accessing file and performing semantic segmentation\n",
        "for files in tqdm(os.listdir(\"./img_align_celeba/\")[4400:]):\n",
        "  image_path = \"img_align_celeba/\"+files\n",
        "  print(image_path)\n",
        "  orig_img = cv2.imread(image_path)\n",
        "  orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
        "  H, W, C = orig_img.shape\n",
        "  #Predicting Depth\n",
        "  disp_pp = predict(orig_img, disp_model)\n",
        "  disp_pp = cv2.resize(disp_pp.squeeze(), (W, H))\n",
        "  disp_pp = disp_pp / disp_pp.max()  \n",
        "  \n",
        "  #Performing Segmentation\n",
        "  seg_map = ss_model.run(orig_img)\n",
        "  #Taking Background\n",
        "  obj_mask = seg_map > 0\n",
        "\n",
        "  result = orig_img.copy()\n",
        "  threshs = [0.8, 0.5, 0.3]\n",
        "  kernels = [5, 9, 11]\n",
        "  fg_masks = [disp_pp < thresh for thresh in threshs]\n",
        "  for i, fg_mask in enumerate(fg_masks):\n",
        "      kernel_size = kernels[i]\n",
        "      #Blurring Image\n",
        "      blurred = cv2.GaussianBlur(orig_img, (kernel_size, kernel_size), 0)\n",
        "      result[fg_mask] = blurred[fg_mask]\n",
        "  result[obj_mask] = orig_img[obj_mask]\n",
        "  plt.imsave('results/'+files,result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XY9tnPDD0Mv1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}